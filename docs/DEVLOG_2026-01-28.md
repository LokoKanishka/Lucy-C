# Devlog — 2026-01-28

Objetivo: que Lucy-C tenga un modo de conversación web (Firefox) con voz fluida y un switch de backend LLM.

## Hechos / Cambios principales

- Web UI dark (port de Proyecto-VSCode) + chat + push-to-talk.
- Modo hands-free (client-side VAD) para envío automático al pausar.
- Fixes robustez:
  - Puerto auto-seleccionado si 5000 está ocupado.
  - Fallback de ASR a CPU/int8 cuando faltan libs de CUDA.
  - TTS (mimic3) opcional + PATH del venv.
  - HTTP fallback `/api/chat` si Socket.IO no conecta.
- Switch de “Brain”:
  - **Ollama (local)**: usa modelo seleccionable (por defecto `gpt-oss:20b`).
  - **lucy (Clawdbot)**: usa Gateway local OpenAI-compatible `/v1/chat/completions`.

## Notas técnicas

- Error observado: `libcublas.so.12` faltante → ASR GPU no usable sin CUDA runtime.
- Error observado: ffmpeg decode EOF por blobs vacíos → se agregó guardrail en JS.

## Próximo paso

- Persistir historia por sesión (session_user) para retomar conversaciones post-reinicio.
